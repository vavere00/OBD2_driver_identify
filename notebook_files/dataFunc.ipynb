{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "from time import mktime\n",
    "from unidecode import unidecode\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib as mpl \n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import arff\n",
    "import datetime\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise all functions\n",
    "#-------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "#print df shape function\n",
    "def print_shape(df1):\n",
    "    for i in range(len(df1)):\n",
    "        print(str(i) + ' '+ str(df1[i].shape))\n",
    "#-------------------------------------------------------------------------        \n",
    "\n",
    "# visualise how total row count changes to NaN value treshold to drop row.\n",
    "def visualise_treshold(df1):\n",
    "    x_ratio = []\n",
    "    y_filtered = []\n",
    "    y_ratio = 0.80\n",
    "    for r in range(70,101,1):\n",
    "        dfnew = []\n",
    "        y_rows = 0\n",
    "        y_ratio = r/100\n",
    "        for i in range(len(df1)):\n",
    "            y_tresh = len(df1[i].columns) * y_ratio\n",
    "            y_rows += df1[i].dropna(axis=0, thresh=y_tresh).shape[0]\n",
    "        x_ratio.append(y_ratio)\n",
    "        y_filtered.append(y_rows)\n",
    "\n",
    "    print(x_ratio)\n",
    "    print(y_filtered)\n",
    "\n",
    "    plt.plot(x_ratio,y_filtered)\n",
    "    plt.ylabel('total rows')\n",
    "    plt.xlabel('portion of noNAN')\n",
    "    plt.show()\n",
    "#-------------------------------------------------------------------------\n",
    "\n",
    "# function - drop rows with lot of NA values and reindex\n",
    "def dropNaNrows(df1,y_ratio=0.9):\n",
    "    for i in range(len(df1)):\n",
    "        y_tresh = len(df1[i].columns) * y_ratio\n",
    "        df1[i] = df1[i].dropna(axis=0, thresh=y_tresh)\n",
    "        df1[i] = df1[i].reset_index(drop=True)\n",
    "#-------------------------------------------------------------------------\n",
    "\n",
    "#drop all constants, but not label\n",
    "def drop_const_column(df1, label='driver'):\n",
    "    dfAll_no_const = []\n",
    "    for i in range(len(df1)):\n",
    "        df_temp = []\n",
    "#         print(str(i) + str(df1[i].shape))\n",
    "        df_temp = (df1[i].loc[:, (df1[i] != df1[i].iloc[0]).any()])\n",
    "        df_temp[label] = df1[i][label]\n",
    "        dfAll_no_const.append(df_temp)\n",
    "#         print(str(i) + str(dfAll_no_const[i].shape))\n",
    "    return dfAll_no_const\n",
    "#-------------------------------------------------------------------------\n",
    "\n",
    "#function - drop columns that do not repeat in other dataframes.\n",
    "def drop_umatching_columns(dfs, label_column = '', drop_column = ''):\n",
    "    #create dictionarry of data frame columns\n",
    "    col_dic = []\n",
    "    for i in range(len(dfs)):\n",
    "        col_dic.append(dfs[i].columns.values.tolist())\n",
    "    print('number of files : ' + str(len(col_dic)))\n",
    "    a = set.intersection(*[set(list1) for list1 in col_dic])\n",
    "    ab = sorted(list(a))\n",
    "    if drop_column != '' : ab.remove(drop_column)\n",
    "    if label_column != '' :\n",
    "        ab.remove(label_column)\n",
    "        ab.append(label_column)\n",
    "#     return ab\n",
    "    for i in range(len(dfs)):\n",
    "        dfs[i] = dfs[i][(ab)]\n",
    "    print('number of same atributes : ' + str(len(ab)))\n",
    "    return dfs\n",
    "#-------------------------------------------------------------------------\n",
    "\n",
    "#function - remove non ascii characters from column names\n",
    "def remove_non_ascii_column(df_all_la):\n",
    "    def remove_non_ascii(text):\n",
    "        return unidecode(unicode(text, encoding = \"utf-8\"))\n",
    "\n",
    "    col_2 = []\n",
    "    col_1 = df_all_la.columns.values.tolist()\n",
    "    for i in range(len(col_1)):\n",
    "        a = remove_non_ascii(col_1[i]).replace(' ', '_')\n",
    "        a = a.replace('%', 'prc')\n",
    "        col_2.append(a)\n",
    "\n",
    "#     df_all_new_names = df_all_la\n",
    "    for i in range(len(df_all_la.columns.values.tolist())):\n",
    "        df_all_la.rename(columns={col_1[i]:col_2[i]},inplace=True)\n",
    "    \n",
    "    df_all_la = df_all_la.reset_index(drop=True)\n",
    "#     return df_all_la\n",
    "#-------------------------------------------------------------------------\n",
    "\n",
    "#convert columns to numeric, 1 df as input\n",
    "def convert_numeric(df_input, expetion_columns=''):\n",
    "    for j in range(len(df_input.columns.values.tolist())-1):\n",
    "        if df_input.columns[j] == 'Device_Time' or df_input.columns[j] == 'driver':\n",
    "            continue\n",
    "        df_input.iloc[:,j] = pd.to_numeric(df_input.iloc[:,j], errors='coerce')\n",
    "        df_input.fillna(0)\n",
    "#-------------------------------------------------------------------------\n",
    "\n",
    "#create csv file \n",
    "def write_csv(dframe, name='', pathtofolder='', delimiter='\\t'):\n",
    "    \n",
    "    #check if path is given\n",
    "    if pathtofolder == '':\n",
    "        path_to_results = '../driving data/colt-all-atributes/concat/'\n",
    "    else:\n",
    "        path_to_results = pathtofolder\n",
    "        \n",
    "    if delimiter=='\\t':\n",
    "        delim = 'tab'\n",
    "    else:\n",
    "        delim = str(delimiter)\n",
    "        \n",
    "    atributes = str(len(dframe.columns.tolist()))\n",
    "    #check if name provided\n",
    "    if name == '' :\n",
    "        name = atributes + '_atributes'\n",
    "    \n",
    "    ts = time.time()\n",
    "    st = datetime.datetime.fromtimestamp(ts).strftime('%Y%m%d_%H%M')\n",
    "    \n",
    "    dframe = dframe.fillna(0)\n",
    "    dframe.to_csv(path_to_results + name +'_'+ delim +'_'+ st + '.csv', sep=delimiter, encoding='utf-8', index=False, na_rep='')\n",
    "#-------------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "#write pandas DataFrame to .arff file for WEKA.\n",
    "#arguments passed: (dataFrame, name='', path_to_folfer='/', label_column='')\n",
    "# dataFrame - comuplsary. dataframe to export \n",
    "# name - optional. Start name of the file appended with tymestamp. if no name only time stamp\n",
    "# path_to_folder - optional. If no path specified, saves in current folder.\n",
    "# label_column - optional. Column containing class labels. Takes last if not provided. \n",
    "def write_arff(dataFrame, name='', pathtofolder='', label_column=''):\n",
    "    if pathtofolder == '':\n",
    "        path_to_results = '../driving data/colt-all-atributes/concat/'\n",
    "        \n",
    "    ts = time.time()\n",
    "    st = datetime.datetime.fromtimestamp(ts).strftime('%Y%m%d_%H%M')\n",
    "    filename = path_to_results + str(name) + '_' + st + '.arff'\n",
    "    # Open the file with writing permission\n",
    "    myfile = open(filename, 'w')\n",
    "    \n",
    "    #write file heading\n",
    "    myfile.write('%blabla\\n\\n')\n",
    "    myfile.write('@relation obd2\\n')\n",
    "    \n",
    "    #meke column names and types\n",
    "    for c in dataFrame.columns:\n",
    "        if (dataFrame[c].dtype == 'object'):\n",
    "            wr = '@attribute ' + str(c) +' {' + (','.join(map(str,dataFrame[c].unique()))) + '}'\n",
    "            myfile.write( wr + '\\n')\n",
    "        else:\n",
    "            wr = '@attribute ' + str(c) +' numeric'\n",
    "            myfile.write( wr + '\\n')\n",
    "    \n",
    "\n",
    "    # Write data to file \n",
    "    myfile.write('\\n@data\\n')\n",
    "    \n",
    "    for j in dataFrame.values:\n",
    "        wr = (','.join(map(str,j)))\n",
    "        myfile.write( wr + '\\n')\n",
    "\n",
    "    # Close the file\n",
    "    myfile.close()\n",
    "    \n",
    "    print(filename + ' created successfuly')\n",
    "#-------------------------------------------------------------------------\n",
    "    \n",
    "\n",
    "#write function to create sliding windows and lag windows\n",
    "def roll_lag(df, window_size, lags=0, y_round=3, atributes_to_ignore=''):\n",
    "    \n",
    "    if df.empty:\n",
    "        print ('no DF passed to function roll_lag')\n",
    "        return\n",
    "    \n",
    "    if window_size < 2:\n",
    "        print('window size should be bigger than 1')\n",
    "        return\n",
    "    \n",
    "    #create temp variables\n",
    "    df_sythetic = pd.DataFrame()\n",
    "    result_mean = {}\n",
    "    result_lag = {}\n",
    "    result_mean.clear()\n",
    "    result_lag.clear()\n",
    "\n",
    "    \n",
    "    for name in df.columns:\n",
    "        if name in atributes_to_ignore:\n",
    "            continue\n",
    "        col_name = str(window_size) + 's_mean_' + name\n",
    "        result = df[name].rolling(window_size).mean().fillna(0).round(y_round)\n",
    "        result_mean.update({ col_name : result })\n",
    "        if lags > 0 :\n",
    "            for j in range(lags):\n",
    "                lag_name = (str(j+1) + '_lag_' + name)\n",
    "                y_lag = (j+1) * (-1)\n",
    "                lag_result = result.shift(periods=y_lag).fillna(0)\n",
    "                result_lag.update({ lag_name : lag_result })\n",
    "                \n",
    "    for x in result_mean:\n",
    "        df_sythetic[x] = result_mean[x]\n",
    "    if len(result_lag) > 0:\n",
    "        for x in result_lag:\n",
    "            df_sythetic[x] = result_lag[x]\n",
    "    \n",
    "    df_new = pd.concat([df_sythetic, df], axis=1, sort=False)\n",
    "    \n",
    "    #sort columns in df\n",
    "    col_list = df_new.columns.values.tolist()\n",
    "    col_list.remove('driver')\n",
    "    col_list = sorted(col_list)\n",
    "    col_list.append('driver')\n",
    "    df_new = df_new[(col_list)]\n",
    "    return df_new\n",
    "#-------------------------------------------------------------------------\n",
    "\n",
    "# normalize data function. \n",
    "def prepr_norm(df, ignore='', l = 'l2'):\n",
    "    df_temp = pd.DataFrame()\n",
    "    col = df.columns.values.tolist()\n",
    "    \n",
    "    if ignore:\n",
    "        for r in ignore:\n",
    "            col.remove(r)\n",
    "\n",
    "    x = df[col].values\n",
    "    normalized_X = preprocessing.normalize(x,norm=l)\n",
    "    df_temp = pd.DataFrame(normalized_X, columns=col, index = df.index)\n",
    "\n",
    "    if ignore:\n",
    "        for r in ignore:    \n",
    "            df_temp[r] = df[r]\n",
    "            \n",
    "    return df_temp\n",
    "#-------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
